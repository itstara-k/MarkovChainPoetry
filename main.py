import os
import random

#read_poems(int) -> str: Returns a string object containing the raw text of n poems; n determines dataset size
def read_poems(num_poems):
    text = ""
    poems = [os.path.join(os.path.join('writing_samples', filename)) for filename in os.listdir('writing_samples')]
    num_poems_read = 0
    for poem in poems:
        if num_poems_read < num_poems:
            with open(poem, encoding="utf8") as f:
                text += f.read()
                num_poems_read += 1
            text += " \\n " #separate poems using a string denoting newline (purpose explained in build_model function)
        else:
            break
        
    return text

#build_model(str) -> dict: Returns a dictionary object containing the Markov model of the input text
def build_model(text):
    text = text.split() #tokenize text
    model = {} #keys = unique tokens/words, values = list of words that immediately follow the key in the input text
    for j in range(len(text)-1):
        word = text[j]
        if word == "\\n" or text[j+1] == "\\n": #skip newline characters used to separate poems so that first word of a poem isn't associated with last word of previous poem
            continue
        word = word.lower() #convert to lowercase for case-insensitive comparison
        if word not in model:
            model[word] = []
        model[word].append(text[j+1].lower())
    
    return model

#generate_text(dict, int) -> str: Returns a string object containing num_words words generated by the Markov model
def generate_text(model, num_words):
    def get_starting_word():
        rand_word = random.choice(list(model.keys())) #choose a random starting word from the model's keys
        if model[rand_word] == []: #if the starting word has no words that follow it, choose another potential starting word via recursion
            return get_starting_word()
        return rand_word
        
    generated_text = get_starting_word()
    while len(generated_text.split()) < num_words:
        last_word = generated_text.split()[-1]
        if last_word not in model:
            generated_text += " " + get_starting_word()
        else:
            next_word = random.choice(model[last_word])
            generated_text += " " + next_word
        
    return generated_text
       
    
def main():
    #generate text from small dataset (5 poems)
    text_small_dataset = read_poems(5)
    model_small_dataset = build_model(text_small_dataset)
    short_poem_small_dataset = generate_text(model_small_dataset, 20) + "\n"
    medium_poem_small_dataset = generate_text(model_small_dataset, 40) + "\n"
    long_poem_small_dataset = generate_text(model_small_dataset, 60) + "\n"
    extra_long_poem_small_dataset = generate_text(model_small_dataset, 80) + "\n"
    print("----Small Dataset----")
    print(short_poem_small_dataset)
    print(medium_poem_small_dataset)
    print(long_poem_small_dataset)
    print(extra_long_poem_small_dataset)
    
    
    #generate text from medium dataset (12 poems)
    text_medium_dataset = read_poems(12)
    model_medium_dataset = build_model(text_medium_dataset)
    short_poem_medium_dataset = generate_text(model_medium_dataset, 20) + "\n"
    medium_poem_medium_dataset = generate_text(model_medium_dataset, 40) + "\n"
    long_poem_medium_dataset = generate_text(model_medium_dataset, 60) + "\n"
    extra_long_poem_medium_dataset = generate_text(model_medium_dataset, 80) + "\n"
    print("----Medium Dataset----")
    print(short_poem_medium_dataset)
    print(medium_poem_medium_dataset)
    print(long_poem_medium_dataset)
    print(extra_long_poem_medium_dataset)
    
    #generate text from large dataset (24 poems)
    text_large_dataset = read_poems(24)
    model_large_dataset = build_model(text_large_dataset)
    short_poem_large_dataset = generate_text(model_large_dataset, 20) + "\n"
    medium_poem_large_dataset = generate_text(model_large_dataset, 40) + "\n"
    long_poem_large_dataset = generate_text(model_large_dataset, 60) + "\n"
    extra_long_poem_large_dataset = generate_text(model_large_dataset, 80) + "\n"
    print("----Large Dataset----")
    print(short_poem_large_dataset)
    print(medium_poem_large_dataset)
    print(long_poem_large_dataset)
    print(extra_long_poem_large_dataset)
    
if __name__ == "__main__":
    main()

